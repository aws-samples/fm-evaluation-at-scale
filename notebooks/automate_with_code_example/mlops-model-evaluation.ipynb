{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bd4cbe6-a20b-457f-a019-aae403938c0c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Orchestrate model evaluation with Amazon SageMaker Pipelines\n",
    "  \n",
    "The goal of this notebook is to provide an implementation of a multi-step SageMaker pipeline that will take care of multiple models evaluation, selection and registration into the SageMaker model registry.  \n",
    "For running this example we will use **LLama-2-7b** models that will be used with default weights or after a finetuning. All the models will be instantiated and finetuned by using [Amazon Sagemaker Jumpstart SDK](https://aws.amazon.com/sagemaker/jumpstart/).  \n",
    "\n",
    "This notebook is also using other Amazon SageMaker components:  \n",
    "\n",
    "[SageMaker Pipelines](https://aws.amazon.com/sagemaker/pipelines/) is a purpose-built workflow orchestration service to automate all phases of machine learning (ML) from data pre-processing to model monitoring. With an intuitive UI and Python SDK you can manage repeatable end-to-end ML pipelines at scale. The native integration with multiple AWS services allows you to customize the ML lifecycle based on your MLOps requirements.\n",
    "SageMaker Model Registry\n",
    "\n",
    "[Amazon SageMaker Model Registry](https://docs.aws.amazon.com/sagemaker/latest/dg/model-registry.html) is a purpose-built metadata store to manage the entire lifecycle of ML models from training to inference. Whether you prefer to store your model artifacts (model framework files, container image) in AWS (Amazon ECR) or outside of AWS in any third party Docker repository, you can now track them all in Amazon SageMaker Model Registry. You also have the flexibility to register a model without read/write permissions to the associated container image. If you want to track an ML model in a private repository, set the optional ‘SkipModelValidation’ parameter to ‘All’ at the time of registration. Later you can also deploy these models for inference in Amazon SageMaker.\n",
    "\n",
    "[Amazon SageMaker Clarify](https://aws.amazon.com/sagemaker/clarify/) provides purpose-built tools to gain greater insights into your ML models and data, based on metrics such as accuracy, robustness, toxicity, and bias to improve model quality and support responsible AI initiative. With the rise of generative AI, data scientists and ML engineers can leverage publicly available foundation models (FMs) to accelerate speed-to-market. To remove the heavy lifting of evaluating and selecting the right FM for your use case, Amazon SageMaker Clarify supports FM evaluation to help you quickly evaluate, compare, and select the best FM for your use case based on a variety of criteria across different tasks within minutes. It allows you to adopt FMs faster and with confidence.\n",
    "To perform evaluation we are using the open source library [FMEval](https://github.com/aws/fmeval) that empowers SageMaker Clarify FM model evaluation.\n",
    "\n",
    "This example is built by following the best practices explained in the blog post [Operationalize LLM Evaluation at Scale using Amazon SageMaker Clarify and MLOps services](https://aws.amazon.com/blogs/machine-learning/operationalize-llm-evaluation-at-scale-using-amazon-sagemaker-clarify-and-mlops-services/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342165dc-1709-456a-ad8f-ec7a5a6e2c05",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Environment setup\n",
    "You need to select `Data Science 3.0 kernel` with `ml.t3.medium` instance to run this notebook.\n",
    "\n",
    "First we need to install required dependencies and import required libraries.  \n",
    "We also make sagemaker SDK aware of the configuration file *config.yml*. \n",
    "This file *config.yml* contains general pipeline parameters like the default pipeline container instance type and the path to the file *dependencies.txt* with the required dependencies.\n",
    "These dependencies will be automatically downloaded from the pipeline container at the start of each pipeline step. We will create *requirements.txt* file later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e8e6ca28a3752",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install fmeval==0.4.0\n",
    "!pip3 install sagemaker==2.208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76487ff0709f4921",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.function_step import step\n",
    "from steps.deploy_llama7b import deploy_llama7b\n",
    "from steps.finetune_llama7b import finetune_llama7b\n",
    "from steps.deploy_finetuned_llama7b import deploy_finetuned_llama7b\n",
    "from steps.selection import selection\n",
    "from steps.preprocess import preprocess\n",
    "from steps.evaluation import evaluation\n",
    "from steps.register import register\n",
    "from steps.cleanup import cleanup\n",
    "from steps.utils import create_training_job_name\n",
    "import os\n",
    "\n",
    "os.environ[\"SAGEMAKER_USER_CONFIG_OVERRIDE\"] = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4d5f58-65e2-4d01-8303-8a2d420e09bf",
   "metadata": {},
   "source": [
    "### Evaluation dataset preparation - preprocess step\n",
    "We save data paths for the pipeline outputs in *output_data_path*.  \n",
    "We then configure **preprocess** our first pipeline step. This step will take care of any data preprocessing that must be done on the evaluation dataset. \n",
    "In this example we are going to download the [SCIQ](https://huggingface.co/datasets/sciq) dataset and create from it two dataset for both instruction and domain adaptation fine-tuning. We also create the evaluation dataset.\n",
    "All the different paths to the datasets will be contained in *preprocess_step_ret*.  \n",
    "Remember the *pipeline_name* as it will be used also in SageMaker Studio to identify our pipeline.  \n",
    "Also mark down the path of the S3 bucket used as output for later consultation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4538466bfbdc3e26",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = \"genai-for-builders-fmops-pipeline\"\n",
    "\n",
    "default_bucket = sagemaker.Session().default_bucket()\n",
    "main_data_path = f\"s3://{default_bucket}\"\n",
    "output_data_path = (main_data_path + \"/datasets/sciq/output_\" + pipeline_name)\n",
    "\n",
    "# You can add your own evaluation dataset code into this step\n",
    "preprocess_step_ret = step(preprocess, name=\"preprocess\")(output_data_path)\n",
    "\n",
    "print(\"The pipeline name is \"+pipeline_name)\n",
    "# Mark the name of this bucket for reviewing the artifacts generated by this pipeline at the end of the execution\n",
    "print(\"Output S3 bucket: \"+output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd50b41df5a91de",
   "metadata": {},
   "source": [
    "### Setup models\n",
    "We are now going to add different models into pipeline. Each model will have an optional **finetune** step, a **deploy** step and finally an **evaluation** step.\n",
    "Before starting the setup we instantiate a couple of supporting array. \n",
    "*model_list* will contain the list of models defined as a dictionary of parameters.  \n",
    "*evaluation_results_ret_list* will contain the result of the evaluation generated by the **evaluation** step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d814fa1c33fb23f9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_list = []\n",
    "evaluation_results_ret_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbaf64feaf794296",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Setup first model: LLama-2-7b from SageMaker Jumpstart\n",
    "For the first model we are using LLama-2-7b available in Amazon SageMaker Jumpstart.\n",
    "We collect all the required parameters into a dictionary and we add it to *model_list* for later use.  \n",
    "We will use one *ml.g5.2xlarge* instance for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0838a5d8ab07589",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup required model parameters\n",
    "model_1 = {\"model_id\": \"meta-textgeneration-llama-2-7b\",\n",
    "           \"model_version\": \"3.0.3\",\n",
    "           \"model_name\": \"llama-2-7b\",\n",
    "           \"endpoint_name\": \"genai-for-builders-fmops-meta-textgeneration-llama-2-7b\",\n",
    "           \"instance_type\": \"ml.g5.2xlarge\",\n",
    "           \"num_instances\": 1}\n",
    "\n",
    "# Save the information of the model in the model_list array for later use\n",
    "model_list.append(model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7ec385385fae3",
   "metadata": {},
   "source": [
    "We then configure **deploy** and **evaluation** data step. Note that **evaluation** step is dependent on both **preprocess** and **deploy** steps because is using the ret values as step inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f73ce22a54ef8f",
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "deploy_llama7b_ret = step(deploy_llama7b, name=\"deploy_llama7b\")(model_1)\n",
    "\n",
    "# Evaluation step is using the output from preprocess (the S3 location of the evaluation dataset file) \n",
    "# and the output of the deploy step (the endpoint name)\n",
    "evaluate_llama7b_ret = step(evaluation,\n",
    "                    name=\"evaluate_llama7b\",\n",
    "                    keep_alive_period_in_seconds=1200\n",
    "                    )(model_1,\n",
    "                      preprocess_step_ret,\n",
    "                      deploy_llama7b_ret)\n",
    "\n",
    "# We save the evaluation output details in the evaluation_results_ret_list array for later use\n",
    "evaluation_results_ret_list.append(evaluate_llama7b_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff5ba2f26142490",
   "metadata": {},
   "source": [
    "### Setup second model: LLama-2-7b from SageMaker Jumpstart to be instruction finetuned\n",
    "The second model in this example is a LLama-2-7b from SageMaker Jumpstart that we are going to finetune with an instruction dataset.  \n",
    "For this model we are going to set parameters required for finetuning job such as:\n",
    "- *finetune_instance_type*: the instance type that will be used to finetune the model\n",
    "- *epoch*: number of finetune epochs\n",
    "- *max_input_length*: maximum input sequence length\n",
    "- *per_device_train_batch_size*: batch size per device\n",
    "- *instruction_tuned*: set to True will force the model to be instruction tuned\n",
    "- *training_data_path*: the S3 data path containing the training dataset\n",
    "\n",
    "We also setup the training job name manually to track it down during the pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f2b32af0481d0",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup required model parameters\n",
    "model_2 = {\n",
    "    \"model_id\": \"meta-textgeneration-llama-2-7b\",\n",
    "    \"model_version\": \"3.*\",\n",
    "    \"model_name\": \"llama-2-7b-instruction-tuned\",\n",
    "    \"endpoint_name\": \"genai-for-builders-fmops-meta-llama-2-7b-instr-finetuned\",\n",
    "    \"finetune_instance_type\": \"ml.g5.12xlarge\",\n",
    "    \"finetune_num_instances\": 1,\n",
    "    \"instance_type\": \"ml.g5.2xlarge\",\n",
    "    \"num_instances\": 1,\n",
    "    \"epoch\": 1,\n",
    "    \"max_input_length\": 512,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"instruction_tuned\": \"True\",\n",
    "    \"chat_dataset\": \"False\",\n",
    "    \"is_finetuned_model\": True\n",
    "}\n",
    "model_2[\"training_job_name\"] = create_training_job_name(model_2[\"model_id\"])\n",
    "\n",
    "# Save the information of the model in the model_list array for later use\n",
    "model_list.append(model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b715608d4b4ad1",
   "metadata": {},
   "source": [
    "We are now going to create the pipeline steps for the second model. For model 2 we add a **finetune** step before the **deploy** and **evaluation** steps.  \n",
    "As before we are saving the evaluation results into *evaluation_results_ret_list* array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa484035f7f5a4",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "finetune_ret = step(finetune_llama7b, name=\"finetune_llama7b_instruction\")(model_2, preprocess_step_ret)\n",
    "\n",
    "# Deploy step is using the output from the finetune step (the training job name)\n",
    "deploy_finetuned_llama7b_ret = step(deploy_finetuned_llama7b, \n",
    "                                    name=\"deploy_finetuned_llama7b_instruction\")(model_2, finetune_ret)\n",
    "\n",
    "# Evaluation step is using the output from preprocess (the S3 location of the evaluation dataset file) \n",
    "# and the output of the deploy step (the endpoint name)\n",
    "evaluate_finetuned_llama7b_instruction_ret = step(evaluation,\n",
    "                    name=\"evaluate_finetuned_llama7b_instr\",\n",
    "                    keep_alive_period_in_seconds=1200,\n",
    "                    )(model_2,\n",
    "                      preprocess_step_ret,\n",
    "                      deploy_finetuned_llama7b_ret)\n",
    "\n",
    "# We save the information of the model in the model_list array for later use\n",
    "evaluation_results_ret_list.append(evaluate_finetuned_llama7b_instruction_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425f135245e0944",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Setup third model: LLama-2-7b-chat from SageMaker Jumpstart to be domain finetuned\n",
    "The third model in this example is a LLama-2-7b-chat from SageMaker Jumpstart that we are going to finetune\n",
    "with a domain dataset.  \n",
    "For this model we are going to set parameters required for finetuning job such as:\n",
    "- *finetune_instance_type*: the instance type that will be used to finetune the model\n",
    "- *epoch*: number of finetune epochs\n",
    "- *max_input_length*: maximum input sequence length\n",
    "- *instruction_tuned*: set to True will force the model to be instruction tuned\n",
    "- *training_data_path*: the S3 data path containing the training dataset\n",
    "- *per_device_train_batch_size*: batch size per device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca692e551ee74f31",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We setup required model parameters\n",
    "model_3 = {\n",
    "    \"model_id\": \"meta-textgeneration-llama-2-7b-f\",\n",
    "    \"model_version\": \"3.*\",\n",
    "    \"model_name\": \"llama-2-7b-chat-domain-tuned\",\n",
    "    \"endpoint_name\": \"genai-for-builders-fmops-meta-llama-2-7b-chat-dom-finetuned\",\n",
    "    \"finetune_instance_type\": \"ml.g5.12xlarge\",\n",
    "    \"finetune_num_instances\": 1,\n",
    "    \"instance_type\": \"ml.g5.2xlarge\",\n",
    "    \"num_instances\": 1,\n",
    "    \"epoch\": 2,\n",
    "    \"max_input_length\": 512,\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"instruction_tuned\": \"False\",\n",
    "    \"chat_dataset\": \"False\",\n",
    "    \"is_finetuned_model\": True\n",
    "}\n",
    "model_3[\"training_job_name\"] = create_training_job_name(model_3[\"model_id\"])\n",
    "\n",
    "# We save the information of the model in the model_list array for later use\n",
    "model_list.append(model_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18801dd08ba069f7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We are now going to create the pipeline steps for model 3 like we did for model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a4b0cf9ab3f0f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "domain_finetune_ret = step(finetune_llama7b, name=\"finetune_llama7b_domain\")(model_3, preprocess_step_ret)\n",
    "\n",
    "# Deploy step is using the output from the finetune step (the training job name)\n",
    "deploy_finetuned_llama7b_dom_ret = step(deploy_finetuned_llama7b, \n",
    "                                    name=\"deploy_finetuned_llama7b_domain\")(model_3, domain_finetune_ret)\n",
    "\n",
    "# Evaluation step is using the output from preprocess (the S3 location of the evaluation dataset file) \n",
    "# and the output of the deploy step (the endpoint name)\n",
    "evaluate_finetuned_llama7b_domain_ret = step(evaluation,\n",
    "                    name=\"evaluate_finetuned_llama7b_dom\",\n",
    "                    keep_alive_period_in_seconds=1200,\n",
    "                    )(model_3,\n",
    "                      preprocess_step_ret,\n",
    "                      deploy_finetuned_llama7b_dom_ret)\n",
    "\n",
    "# We save the information of the model in the model_list array for later use\n",
    "evaluation_results_ret_list.append(evaluate_finetuned_llama7b_domain_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f23d56614aea50",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Select best model and register it in SageMaker Model Registry\n",
    "Now it's time to select best model. To do so we create a pipeline step dedicated to the best model **selection**.\n",
    "The selection is using the output of all the models' evaluation.\n",
    "The output of the **selection** step is the best model name. We will use the best model name in the **register** step.  \n",
    "The **register** step will also need a package group and description name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b05c18a5295ce0a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluation step is using the output from the evaluation steps of all the models\n",
    "selection_ret = step(selection, name=\"best_model_selection\")(*evaluation_results_ret_list)\n",
    "\n",
    "# Set a package group name and description\n",
    "model_package_group_name = \"GenAIForBuilderFMOpsEvaluationPipeline\"\n",
    "model_package_group_description = \"GenAI For Builder FMOps Evaluation Pipeline Model Registry\"\n",
    "\n",
    "# We will register the best model in the model register. The best model name is contained in the return object of the selection step\n",
    "register_ret = step(register, name=\"best_model_register\")(model_list,\n",
    "                                                          output_data_path,\n",
    "                                                          model_package_group_name,\n",
    "                                                          model_package_group_description,\n",
    "                                                          selection_ret,\n",
    "                                                          *evaluation_results_ret_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478f53e262aafb7c",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "The last pipeline step is dedicated to cleanup all the resource that we are going to instantiate with the pipeline.\n",
    "For each model we create a **cleanup** step to be executed in parallel. All **cleanup** steps will fan-out after **register** step as they are dependent on its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71735d24ab99ad89",
   "metadata": {
    "collapsed": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We need to create a cleanup step for each model. We collect the return objects to add them later in the pipeline creation function\n",
    "cleanup_ret_list = []\n",
    "\n",
    "for model in model_list:\n",
    "    # We append register_ret to connect the register and cleanup steps together\n",
    "    cleanup_ret = step(cleanup, name=\"cleanup_\"+model[\"model_name\"])(model[\"endpoint_name\"], register_ret)\n",
    "    cleanup_ret_list.append(cleanup_ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce0babb-70c2-4b2b-bde8-f0986109fde6",
   "metadata": {},
   "source": [
    "### Creating and launching the pipeline\n",
    "We are finally ready to create and launch the pipeline but before doing that we will need to create a requirements.txt file.\n",
    "As a best practice we are reading the current sagemaker library version that we are using to create the pipeline and set it as a requirement into the requirement file.\n",
    "Keeping the same sagemaker version in the creation and running phase will allow us to avoid any deserialization issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c682ddc-f4fc-4ef4-8081-d753032f2888",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if os.path.exists(\"requirements.txt\"):\n",
    "    os.remove(\"requirements.txt\")\n",
    "\n",
    "with open('requirements.txt', 'w') as req_file:\n",
    "    req_file.write(\"fmeval==0.4.0\\n\")\n",
    "    req_file.write(\"sagemaker==\" + str(sagemaker.__version__) + \"\\n\")\n",
    "    req_file.write(\"datasets\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b5abfcc508e191",
   "metadata": {},
   "source": [
    "In the last cell of this notebook we are creating the pipeline and serializing it to S3. \n",
    "Don't forget to attach the execution role with sufficient permission and the return results from the last steps of our pipeline.\n",
    "We are now ready to start the pipeline execution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f091649f823362",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "pipeline = Pipeline(name=pipeline_name, steps=cleanup_ret_list)\n",
    "pipeline.upsert(role)\n",
    "pipeline.start()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
